{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74385764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "✓ All libraries imported successfully!\n",
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"\\n✓ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff21f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading TLKM.JK data from 2015-01-01 to 2025-11-04...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>TLKM.JK</th>\n",
       "      <th>TLKM.JK</th>\n",
       "      <th>TLKM.JK</th>\n",
       "      <th>TLKM.JK</th>\n",
       "      <th>TLKM.JK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>1755.473389</td>\n",
       "      <td>1770.818436</td>\n",
       "      <td>1749.335370</td>\n",
       "      <td>1770.818436</td>\n",
       "      <td>18992100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>1740.128296</td>\n",
       "      <td>1749.335324</td>\n",
       "      <td>1730.921268</td>\n",
       "      <td>1749.335324</td>\n",
       "      <td>49940700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>1727.852295</td>\n",
       "      <td>1740.128333</td>\n",
       "      <td>1718.645267</td>\n",
       "      <td>1724.783286</td>\n",
       "      <td>47892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>1724.783447</td>\n",
       "      <td>1761.611564</td>\n",
       "      <td>1715.576418</td>\n",
       "      <td>1758.542554</td>\n",
       "      <td>70076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>1740.128296</td>\n",
       "      <td>1746.266315</td>\n",
       "      <td>1733.990277</td>\n",
       "      <td>1743.197305</td>\n",
       "      <td>56582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-28</th>\n",
       "      <td>3400.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "      <td>3270.000000</td>\n",
       "      <td>3330.000000</td>\n",
       "      <td>143082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29</th>\n",
       "      <td>3290.000000</td>\n",
       "      <td>3390.000000</td>\n",
       "      <td>3270.000000</td>\n",
       "      <td>3390.000000</td>\n",
       "      <td>93073800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30</th>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3310.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>3290.000000</td>\n",
       "      <td>83523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-31</th>\n",
       "      <td>3210.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>126790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-03</th>\n",
       "      <td>3350.000000</td>\n",
       "      <td>3380.000000</td>\n",
       "      <td>3210.000000</td>\n",
       "      <td>3210.000000</td>\n",
       "      <td>107151300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2671 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price             Close         High          Low         Open     Volume\n",
       "Ticker          TLKM.JK      TLKM.JK      TLKM.JK      TLKM.JK    TLKM.JK\n",
       "Date                                                                     \n",
       "2015-01-02  1755.473389  1770.818436  1749.335370  1770.818436   18992100\n",
       "2015-01-05  1740.128296  1749.335324  1730.921268  1749.335324   49940700\n",
       "2015-01-06  1727.852295  1740.128333  1718.645267  1724.783286   47892100\n",
       "2015-01-07  1724.783447  1761.611564  1715.576418  1758.542554   70076600\n",
       "2015-01-08  1740.128296  1746.266315  1733.990277  1743.197305   56582500\n",
       "...                 ...          ...          ...          ...        ...\n",
       "2025-10-28  3400.000000  3480.000000  3270.000000  3330.000000  143082100\n",
       "2025-10-29  3290.000000  3390.000000  3270.000000  3390.000000   93073800\n",
       "2025-10-30  3250.000000  3310.000000  3200.000000  3290.000000   83523100\n",
       "2025-10-31  3210.000000  3250.000000  3150.000000  3200.000000  126790400\n",
       "2025-11-03  3350.000000  3380.000000  3210.000000  3210.000000  107151300\n",
       "\n",
       "[2671 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data\n",
    "ticker = 'TLKM.JK'\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2025-11-04'\n",
    "\n",
    "print(f\"\\nDownloading {ticker} data from {start_date} to {end_date}...\")\n",
    "df_raw = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c349baa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Data downloaded successfully!\n",
      "Total records: 2671\n",
      "Date range: 2015-01-02 00:00:00 to 2025-11-03 00:00:00\n",
      "Trading days: 2671 days\n",
      "\n",
      "Data structure verification:\n",
      "Volume type: <class 'pandas.core.series.Series'>\n",
      "Volume shape: (2671,)\n"
     ]
    }
   ],
   "source": [
    "# Fix multi-level columns issue\n",
    "if isinstance(df_raw.columns, pd.MultiIndex):\n",
    "    df_raw.columns = df_raw.columns.droplevel(1)\n",
    "\n",
    "# Force convert to proper DataFrame with 1D Series\n",
    "df = pd.DataFrame({\n",
    "    'Open': df_raw['Open'].squeeze(),\n",
    "    'High': df_raw['High'].squeeze(),\n",
    "    'Low': df_raw['Low'].squeeze(),\n",
    "    'Close': df_raw['Close'].squeeze(),\n",
    "    'Volume': df_raw['Volume'].squeeze()\n",
    "}, index=df_raw.index)\n",
    "\n",
    "print(f\"\\n✓ Data downloaded successfully!\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(f\"Trading days: {len(df)} days\")\n",
    "\n",
    "# Verify data structure\n",
    "print(\"\\nData structure verification:\")\n",
    "print(f\"Volume type: {type(df['Volume'])}\")\n",
    "print(f\"Volume shape: {df['Volume'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c73801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features: ['Open', 'High', 'Low', 'Close']\n",
      "Target variable: Close (for prediction)\n",
      "Data shape: (2671, 4)\n"
     ]
    }
   ],
   "source": [
    "# Select OHLC features\n",
    "features = ['Open', 'High', 'Low', 'Close']\n",
    "data = df[features].copy()\n",
    "\n",
    "print(f\"\\nSelected features: {features}\")\n",
    "print(f\"Target variable: Close (for prediction)\")\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aacaaa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date is already set as index: Date\n",
      "Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    }
   ],
   "source": [
    "# Date is already index from yfinance\n",
    "print(f\"Date is already set as index: {data.index.name}\")\n",
    "print(f\"Index type: {type(data.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6cd40bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total data: 2671 days\n",
      "\n",
      "Train set: 1869 days (70.0%)\n",
      "  Period: 2015-01-02 00:00:00 to 2022-07-01 00:00:00\n",
      "\n",
      "Validation set: 400 days (15.0%)\n",
      "  Period: 2022-07-04 00:00:00 to 2024-02-19 00:00:00\n",
      "\n",
      "Test set: 402 days (15.1%)\n",
      "  Period: 2024-02-20 00:00:00 to 2025-11-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate split indices\n",
    "train_size = int(len(data) * 0.70)\n",
    "val_size = int(len(data) * 0.15)\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "# Split data\n",
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size:train_size+val_size]\n",
    "test_data = data.iloc[train_size+val_size:]\n",
    "\n",
    "print(f\"\\nTotal data: {len(data)} days\")\n",
    "print(f\"\\nTrain set: {len(train_data)} days ({len(train_data)/len(data)*100:.1f}%)\")\n",
    "print(f\"  Period: {train_data.index[0]} to {train_data.index[-1]}\")\n",
    "print(f\"\\nValidation set: {len(val_data)} days ({len(val_data)/len(data)*100:.1f}%)\")\n",
    "print(f\"  Period: {val_data.index[0]} to {val_data.index[-1]}\")\n",
    "print(f\"\\nTest set: {len(test_data)} days ({len(test_data)/len(data)*100:.1f}%)\")\n",
    "print(f\"  Period: {test_data.index[0]} to {test_data.index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbfe3622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Scaler fitted on TRAINING data only!\n",
      "\n",
      "Original value range:\n",
      "  Min: [1614.92643214 1649.75817871 1573.76164073 1646.59179688]\n",
      "  Max: [3922.42499281 3922.42499281 3817.28796924 3857.7253418 ]\n",
      "\n",
      "Scaled value range: [0, 1]\n",
      "\n",
      "Scaled data shapes:\n",
      "  Train: (1869, 4)\n",
      "  Val: (400, 4)\n",
      "  Test: (402, 4)\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit ONLY on training data\n",
    "train_scaled = scaler.fit_transform(train_data)\n",
    "val_scaled = scaler.transform(val_data)\n",
    "test_scaled = scaler.transform(test_data)\n",
    "\n",
    "print(\"\\n✓ Scaler fitted on TRAINING data only!\")\n",
    "print(f\"\\nOriginal value range:\")\n",
    "print(f\"  Min: {train_data.min().values}\")\n",
    "print(f\"  Max: {train_data.max().values}\")\n",
    "print(f\"\\nScaled value range: [0, 1]\")\n",
    "print(f\"\\nScaled data shapes:\")\n",
    "print(f\"  Train: {train_scaled.shape}\")\n",
    "print(f\"  Val: {val_scaled.shape}\")\n",
    "print(f\"  Test: {test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0223b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size, horizon=3):\n",
    "    \"\"\"\n",
    "    Create sequences for multi-horizon forecasting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy array\n",
    "        Scaled data with shape (samples, features)\n",
    "    window_size : int\n",
    "        Number of time steps to look back\n",
    "    horizon : int\n",
    "        Number of time steps to forecast (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : numpy array\n",
    "        Input sequences with shape (samples, window_size, features)\n",
    "    y : numpy array\n",
    "        Target values with shape (samples, horizon)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(data) - window_size - horizon + 1):\n",
    "        # Input: window_size time steps of all features\n",
    "        X.append(data[i:i+window_size])\n",
    "        \n",
    "        # Output: next 'horizon' Close prices\n",
    "        # Close is at index 3 in [Open, High, Low, Close]\n",
    "        y.append(data[i+window_size:i+window_size+horizon, 3])\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "485028fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using best window size: 30\n",
      "\n",
      "Sequences created:\n",
      "  Train: X=(1837, 30, 4), y=(1837, 3)\n",
      "  Val:   X=(368, 30, 4), y=(368, 3)\n",
      "  Test:  X=(370, 30, 4), y=(370, 3)\n"
     ]
    }
   ],
   "source": [
    "# CREATE SEQUENCES WITH BEST WINDOW SIZE\n",
    "best_window_size = 30\n",
    "horizon = 3\n",
    "print(f\"\\nUsing best window size: {best_window_size}\")\n",
    "\n",
    "# Create sequences for train, val, test with BEST window size\n",
    "X_train, y_train = create_sequences(train_scaled, best_window_size, horizon)\n",
    "X_val, y_val = create_sequences(val_scaled, best_window_size, horizon)\n",
    "X_test, y_test = create_sequences(test_scaled, best_window_size, horizon)\n",
    "\n",
    "print(f\"\\nSequences created:\")\n",
    "print(f\"  Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Val:   X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"  Test:  X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "161ab6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_WINDOW_SIZE = 30\n",
    "FINAL_HORIZON = 3\n",
    "FINAL_UNITS = 128\n",
    "FINAL_LR = 0.001\n",
    "FINAL_BATCH = 16\n",
    "N_FEATURES = 4  # Open, High, Low, Close\n",
    "\n",
    "def build_final_model(model_type: str,\n",
    "                      window_size: int = FINAL_WINDOW_SIZE,\n",
    "                      n_features: int = N_FEATURES,\n",
    "                      units: int = FINAL_UNITS,\n",
    "                      lr: float = FINAL_LR,\n",
    "                      horizon: int = FINAL_HORIZON):\n",
    "    model_type = model_type.upper().strip()\n",
    "    if model_type not in [\"LSTM\", \"GRU\"]:\n",
    "        raise ValueError(\"model_type harus 'LSTM' atau 'GRU'\")\n",
    "\n",
    "    RNN = LSTM if model_type == \"LSTM\" else GRU\n",
    "\n",
    "    model = Sequential([\n",
    "        RNN(units, return_sequences=True, input_shape=(window_size, n_features)),\n",
    "        Dropout(0.2),\n",
    "        RNN(units),\n",
    "        Dropout(0.2),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e298b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0101 - mae: 0.0632\n",
      "Epoch 1: val_loss improved from inf to 0.00250, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 15s 67ms/step - loss: 0.0101 - mae: 0.0632 - val_loss: 0.0025 - val_mae: 0.0405\n",
      "Epoch 2/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0036 - mae: 0.0452\n",
      "Epoch 2: val_loss improved from 0.00250 to 0.00193, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.0036 - mae: 0.0452 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 3/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0032 - mae: 0.0420\n",
      "Epoch 3: val_loss did not improve from 0.00193\n",
      "115/115 [==============================] - 6s 55ms/step - loss: 0.0032 - mae: 0.0420 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 4/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0031 - mae: 0.0413\n",
      "Epoch 4: val_loss did not improve from 0.00193\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0031 - mae: 0.0413 - val_loss: 0.0021 - val_mae: 0.0351\n",
      "Epoch 5/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0027 - mae: 0.0389\n",
      "Epoch 5: val_loss improved from 0.00193 to 0.00172, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 6/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0027 - mae: 0.0389\n",
      "Epoch 6: val_loss improved from 0.00172 to 0.00120, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 7/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0024 - mae: 0.0370\n",
      "Epoch 7: val_loss did not improve from 0.00120\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0020 - val_mae: 0.0367\n",
      "Epoch 8/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0023 - mae: 0.0361\n",
      "Epoch 8: val_loss did not improve from 0.00120\n",
      "115/115 [==============================] - 5s 48ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 9/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0024 - mae: 0.0371\n",
      "Epoch 9: val_loss did not improve from 0.00120\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.0024 - mae: 0.0371 - val_loss: 0.0014 - val_mae: 0.0291\n",
      "Epoch 10/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0351\n",
      "Epoch 10: val_loss did not improve from 0.00120\n",
      "115/115 [==============================] - 6s 55ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0026 - val_mae: 0.0440\n",
      "Epoch 11/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0022 - mae: 0.0352\n",
      "Epoch 11: val_loss improved from 0.00120 to 0.00095, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 9.4887e-04 - val_mae: 0.0233\n",
      "Epoch 12/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0337\n",
      "Epoch 12: val_loss did not improve from 0.00095\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0028 - val_mae: 0.0458\n",
      "Epoch 13/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0327\n",
      "Epoch 13: val_loss did not improve from 0.00095\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0261\n",
      "Epoch 14/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0317\n",
      "Epoch 14: val_loss did not improve from 0.00095\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0014 - val_mae: 0.0305\n",
      "Epoch 15/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0334\n",
      "Epoch 15: val_loss did not improve from 0.00095\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0017 - val_mae: 0.0342\n",
      "Epoch 16/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0324\n",
      "Epoch 16: val_loss did not improve from 0.00095\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 17/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0017 - mae: 0.0312\n",
      "Epoch 17: val_loss did not improve from 0.00095\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 18/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0018 - mae: 0.0314\n",
      "Epoch 18: val_loss did not improve from 0.00095\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0019 - val_mae: 0.0372\n",
      "Epoch 19/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0017 - mae: 0.0310\n",
      "Epoch 19: val_loss improved from 0.00095 to 0.00088, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 8.8010e-04 - val_mae: 0.0223\n",
      "Epoch 20/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0017 - mae: 0.0308\n",
      "Epoch 20: val_loss did not improve from 0.00088\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0013 - val_mae: 0.0290\n",
      "Epoch 21/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0301\n",
      "Epoch 21: val_loss did not improve from 0.00088\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 9.8381e-04 - val_mae: 0.0240\n",
      "Epoch 22/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0297\n",
      "Epoch 22: val_loss improved from 0.00088 to 0.00087, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 8.7406e-04 - val_mae: 0.0224\n",
      "Epoch 23/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0289\n",
      "Epoch 23: val_loss improved from 0.00087 to 0.00079, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 55ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 7.9153e-04 - val_mae: 0.0210\n",
      "Epoch 24/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0295\n",
      "Epoch 24: val_loss did not improve from 0.00079\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 8.5843e-04 - val_mae: 0.0220\n",
      "Epoch 25/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0292\n",
      "Epoch 25: val_loss did not improve from 0.00079\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 9.5616e-04 - val_mae: 0.0239\n",
      "Epoch 26/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0284\n",
      "Epoch 26: val_loss did not improve from 0.00079\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0272\n",
      "Epoch 27/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0014 - mae: 0.0276\n",
      "Epoch 27: val_loss did not improve from 0.00079\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 9.8003e-04 - val_mae: 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0291\n",
      "Epoch 28: val_loss did not improve from 0.00079\n",
      "115/115 [==============================] - 7s 61ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0020 - val_mae: 0.0384\n",
      "Epoch 29/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0276\n",
      "Epoch 29: val_loss did not improve from 0.00079\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 8.1521e-04 - val_mae: 0.0213\n",
      "Epoch 30/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0285\n",
      "Epoch 30: val_loss improved from 0.00079 to 0.00077, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 55ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 7.6505e-04 - val_mae: 0.0206\n",
      "Epoch 31/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0284\n",
      "Epoch 31: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 9.7883e-04 - val_mae: 0.0243\n",
      "Epoch 32/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0269\n",
      "Epoch 32: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 8.6653e-04 - val_mae: 0.0223\n",
      "Epoch 33/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0273\n",
      "Epoch 33: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 8.4857e-04 - val_mae: 0.0221\n",
      "Epoch 34/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0263\n",
      "Epoch 34: val_loss improved from 0.00077 to 0.00074, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 7.3888e-04 - val_mae: 0.0202\n",
      "Epoch 35/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0267\n",
      "Epoch 35: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 55ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0015 - val_mae: 0.0316\n",
      "Epoch 36/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0268\n",
      "Epoch 36: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 8.1151e-04 - val_mae: 0.0216\n",
      "Epoch 37/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0261\n",
      "Epoch 37: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 7.9795e-04 - val_mae: 0.0214\n",
      "Epoch 38/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0261\n",
      "Epoch 38: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0013 - val_mae: 0.0289\n",
      "Epoch 39/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0255\n",
      "Epoch 39: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0013 - val_mae: 0.0298\n",
      "Epoch 40/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0260\n",
      "Epoch 40: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 7.7135e-04 - val_mae: 0.0209\n",
      "Epoch 41/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0257\n",
      "Epoch 41: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0263\n",
      "Epoch 42/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0270\n",
      "Epoch 42: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 8.8766e-04 - val_mae: 0.0230\n",
      "Epoch 43/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0260\n",
      "Epoch 43: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 7.8075e-04 - val_mae: 0.0211\n",
      "Epoch 44/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0252\n",
      "Epoch 44: val_loss improved from 0.00074 to 0.00074, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 7.3796e-04 - val_mae: 0.0202\n",
      "Epoch 45/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0255\n",
      "Epoch 45: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 7.9310e-04 - val_mae: 0.0211\n",
      "Epoch 46/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0254\n",
      "Epoch 46: val_loss did not improve from 0.00074\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 7.5366e-04 - val_mae: 0.0205\n",
      "Epoch 47/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0257\n",
      "Epoch 47: val_loss improved from 0.00074 to 0.00072, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 7.1949e-04 - val_mae: 0.0199\n",
      "Epoch 48/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0255\n",
      "Epoch 48: val_loss improved from 0.00072 to 0.00072, saving model to best_model_lstm.keras\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 7.1647e-04 - val_mae: 0.0199\n",
      "Epoch 49/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0253\n",
      "Epoch 49: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 7.8363e-04 - val_mae: 0.0211\n",
      "Epoch 50/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0252\n",
      "Epoch 50: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 9.1523e-04 - val_mae: 0.0232\n",
      "Epoch 51/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0256\n",
      "Epoch 51: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 8s 70ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 0.0015 - val_mae: 0.0322\n",
      "Epoch 52/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0251\n",
      "Epoch 52: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 6s 55ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 7.5361e-04 - val_mae: 0.0206\n",
      "Epoch 53/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0253\n",
      "Epoch 53: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 5s 47ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 7.4981e-04 - val_mae: 0.0204\n",
      "Epoch 54/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0256\n",
      "Epoch 54: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.0016 - val_mae: 0.0342\n",
      "Epoch 55/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0252\n",
      "Epoch 55: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0012 - val_mae: 0.0286\n",
      "Epoch 56/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0255\n",
      "Epoch 56: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 8s 70ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 7.2028e-04 - val_mae: 0.0199\n",
      "Epoch 57/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0253\n",
      "Epoch 57: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 7.7151e-04 - val_mae: 0.0209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0245\n",
      "Epoch 58: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 7.2496e-04 - val_mae: 0.0201\n",
      "Epoch 59/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0247\n",
      "Epoch 59: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 7s 61ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 7.8907e-04 - val_mae: 0.0212\n",
      "Epoch 60/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0250\n",
      "Epoch 60: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 7.3730e-04 - val_mae: 0.0203\n",
      "Epoch 61/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0248\n",
      "Epoch 61: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 7s 62ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0253\n",
      "Epoch 62/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0243\n",
      "Epoch 62: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 10s 85ms/step - loss: 0.0010 - mae: 0.0243 - val_loss: 7.5104e-04 - val_mae: 0.0206\n",
      "Epoch 63/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0243Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00072\n",
      "115/115 [==============================] - 8s 70ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 7.6331e-04 - val_mae: 0.0206\n",
      "Epoch 63: early stopping\n",
      "Epoch 1/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0137 - mae: 0.0707\n",
      "Epoch 1: val_loss improved from inf to 0.00163, saving model to best_model_gru.keras\n",
      "115/115 [==============================] - 16s 62ms/step - loss: 0.0137 - mae: 0.0707 - val_loss: 0.0016 - val_mae: 0.0327\n",
      "Epoch 2/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0032 - mae: 0.0426\n",
      "Epoch 2: val_loss improved from 0.00163 to 0.00140, saving model to best_model_gru.keras\n",
      "115/115 [==============================] - 5s 43ms/step - loss: 0.0032 - mae: 0.0427 - val_loss: 0.0014 - val_mae: 0.0300\n",
      "Epoch 3/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0029 - mae: 0.0405\n",
      "Epoch 3: val_loss did not improve from 0.00140\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0029 - mae: 0.0405 - val_loss: 0.0047 - val_mae: 0.0592\n",
      "Epoch 4/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0028 - mae: 0.0401\n",
      "Epoch 4: val_loss improved from 0.00140 to 0.00107, saving model to best_model_gru.keras\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 5/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0375\n",
      "Epoch 5: val_loss did not improve from 0.00107\n",
      "115/115 [==============================] - 5s 43ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0015 - val_mae: 0.0297\n",
      "Epoch 6/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0378\n",
      "Epoch 6: val_loss did not improve from 0.00107\n",
      "115/115 [==============================] - 5s 45ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0024 - val_mae: 0.0422\n",
      "Epoch 7/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0022 - mae: 0.0355\n",
      "Epoch 7: val_loss did not improve from 0.00107\n",
      "115/115 [==============================] - 5s 45ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0016 - val_mae: 0.0332\n",
      "Epoch 8/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0342\n",
      "Epoch 8: val_loss did not improve from 0.00107\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0022 - val_mae: 0.0383\n",
      "Epoch 9/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0023 - mae: 0.0363\n",
      "Epoch 9: val_loss did not improve from 0.00107\n",
      "115/115 [==============================] - 5s 44ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0014 - val_mae: 0.0289\n",
      "Epoch 10/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0329\n",
      "Epoch 10: val_loss did not improve from 0.00107\n",
      "115/115 [==============================] - 5s 41ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0020 - val_mae: 0.0367\n",
      "Epoch 11/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0327\n",
      "Epoch 11: val_loss improved from 0.00107 to 0.00084, saving model to best_model_gru.keras\n",
      "115/115 [==============================] - 5s 40ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 8.4297e-04 - val_mae: 0.0220\n",
      "Epoch 12/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0325\n",
      "Epoch 12: val_loss did not improve from 0.00084\n",
      "115/115 [==============================] - 5s 45ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0030 - val_mae: 0.0487\n",
      "Epoch 13/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0017 - mae: 0.0311\n",
      "Epoch 13: val_loss improved from 0.00084 to 0.00077, saving model to best_model_gru.keras\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 7.7316e-04 - val_mae: 0.0208\n",
      "Epoch 14/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0304\n",
      "Epoch 14: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 4s 39ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 8.6285e-04 - val_mae: 0.0226\n",
      "Epoch 15/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0016 - mae: 0.0305\n",
      "Epoch 15: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 5s 40ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 16/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0017 - mae: 0.0310\n",
      "Epoch 16: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 5s 41ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0010 - val_mae: 0.0252\n",
      "Epoch 17/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0301\n",
      "Epoch 17: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 5s 40ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0010 - val_mae: 0.0246\n",
      "Epoch 18/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0016 - mae: 0.0298\n",
      "Epoch 18: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0015 - val_mae: 0.0324\n",
      "Epoch 19/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0303\n",
      "Epoch 19: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 5s 43ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 8.2198e-04 - val_mae: 0.0220\n",
      "Epoch 20/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0016 - mae: 0.0295\n",
      "Epoch 20: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0014 - val_mae: 0.0304\n",
      "Epoch 21/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0291\n",
      "Epoch 21: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 5s 46ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 8.0104e-04 - val_mae: 0.0212\n",
      "Epoch 22/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0277\n",
      "Epoch 22: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 9.1458e-04 - val_mae: 0.0233\n",
      "Epoch 23/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0280\n",
      "Epoch 23: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 8.4686e-04 - val_mae: 0.0220\n",
      "Epoch 24/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0014 - mae: 0.0280\n",
      "Epoch 24: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0304\n",
      "Epoch 25: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0013 - val_mae: 0.0296\n",
      "Epoch 26/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0282\n",
      "Epoch 26: val_loss did not improve from 0.00077\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0014 - val_mae: 0.0310\n",
      "Epoch 27/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0265\n",
      "Epoch 27: val_loss improved from 0.00077 to 0.00075, saving model to best_model_gru.keras\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 7.4790e-04 - val_mae: 0.0204\n",
      "Epoch 28/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0275\n",
      "Epoch 28: val_loss did not improve from 0.00075\n",
      "115/115 [==============================] - 5s 47ms/step - loss: 0.0013 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 29/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0268\n",
      "Epoch 29: val_loss did not improve from 0.00075\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 7.7648e-04 - val_mae: 0.0209\n",
      "Epoch 30/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 30: val_loss improved from 0.00075 to 0.00071, saving model to best_model_gru.keras\n",
      "115/115 [==============================] - 5s 45ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 7.1364e-04 - val_mae: 0.0199\n",
      "Epoch 31/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0274\n",
      "Epoch 31: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 43ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 9.5855e-04 - val_mae: 0.0238\n",
      "Epoch 32/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0266\n",
      "Epoch 32: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 44ms/step - loss: 0.0012 - mae: 0.0266 - val_loss: 7.9868e-04 - val_mae: 0.0212\n",
      "Epoch 33/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 33: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 45ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0012 - val_mae: 0.0276\n",
      "Epoch 34/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0264\n",
      "Epoch 34: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 41ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 8.5415e-04 - val_mae: 0.0223\n",
      "Epoch 35/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0266\n",
      "Epoch 35: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 41ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 9.7245e-04 - val_mae: 0.0242\n",
      "Epoch 36/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0269\n",
      "Epoch 36: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 9.6266e-04 - val_mae: 0.0245\n",
      "Epoch 37/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0261\n",
      "Epoch 37: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 45ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0015 - val_mae: 0.0320\n",
      "Epoch 38/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0261\n",
      "Epoch 38: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 43ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 7.8508e-04 - val_mae: 0.0210\n",
      "Epoch 39/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0262\n",
      "Epoch 39: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 7.7807e-04 - val_mae: 0.0209\n",
      "Epoch 40/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0255\n",
      "Epoch 40: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0277\n",
      "Epoch 41/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0254\n",
      "Epoch 41: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 43ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 9.8664e-04 - val_mae: 0.0242\n",
      "Epoch 42/150\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0263\n",
      "Epoch 42: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 43ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0033 - val_mae: 0.0518\n",
      "Epoch 43/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0263\n",
      "Epoch 43: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 41ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 7.6631e-04 - val_mae: 0.0209\n",
      "Epoch 44/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0258\n",
      "Epoch 44: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.0012 - mae: 0.0258 - val_loss: 7.4850e-04 - val_mae: 0.0205\n",
      "Epoch 45/150\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0255Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00071\n",
      "115/115 [==============================] - 5s 41ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 45: early stopping\n",
      "Saved: best_model_lstm.keras and best_model_gru.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train_final_fixed(X_train, y_train, X_val, y_val, model_type: str):\n",
    "    model = build_final_model(model_type=model_type)\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    ckpt_path = f\"best_model_{model_type.lower()}.keras\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        ckpt_path,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=FINAL_BATCH,\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    return model, history, ckpt_path\n",
    "\n",
    "# Train final models (tanpa tuning apa pun)\n",
    "final_model_lstm, hist_lstm, path_lstm = train_final_fixed(X_train, y_train, X_val, y_val, \"LSTM\")\n",
    "final_model_gru,  hist_gru,  path_gru  = train_final_fixed(X_train, y_train, X_val, y_val, \"GRU\")\n",
    "\n",
    "print(\"Saved:\", path_lstm, \"and\", path_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38826034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: scaler.pkl and meta.json\n"
     ]
    }
   ],
   "source": [
    "import json, joblib\n",
    "\n",
    "# scaler = MinMaxScaler() yang Anda FIT pada TRAIN (bukan val/test)\n",
    "\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "meta = {\n",
    "    \"features\": [\"Open\", \"High\", \"Low\", \"Close\"],\n",
    "    \"target_col\": \"Close\",\n",
    "    \"window_size\": FINAL_WINDOW_SIZE,\n",
    "    \"horizon\": FINAL_HORIZON,\n",
    "    \"units\": FINAL_UNITS,\n",
    "    \"lr\": FINAL_LR,\n",
    "    \"batch_size\": FINAL_BATCH\n",
    "}\n",
    "with open(\"meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved: scaler.pkl and meta.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
